{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/annotation_import/pdf.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/annotation_import/pdf.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# PDF Prediction Import\n",
        "\n",
        "Supported predictions for PDF assets\n",
        "\n",
        "Python Annotation Types \n",
        "- Checklist classification \n",
        "- Radio classification \n",
        "- Free text classifications \n",
        "- Entities \n",
        "\n",
        "NDJson \n",
        "- Checklist classification (including nested classifications)\n",
        "- Radio classificaations (including nested classifications)\n",
        "- Free text classifications \n",
        "- Bouding box \n",
        "- Entities"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Setup"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install -q 'labelbox[data]'"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "import uuid\n",
        "import labelbox as lb\n",
        "import labelbox.types as lb_types\n",
        "from labelbox.schema.queue_mode import QueueMode"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Replace with your API key \n",
        "Guides on how to create an API key : https://docs.labelbox.com/docs/create-an-api-key"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Add your api key\n",
        "API_KEY = \"\"\n",
        "client = lb.Client(api_key=API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Supported Predictions"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "########## Entity ##########\n",
        "\n",
        "# Annotation Types\n",
        "entities_prediction = lb_types.ObjectAnnotation(        \n",
        "    name=\"named_entity\",\n",
        "    confidence=0.5, \n",
        "    value= lb_types.DocumentEntity(\n",
        "        name=\"named_entity\",\n",
        "        textSelections=[\n",
        "            lb_types.DocumentTextSelection(\n",
        "                token_ids=[],\n",
        "                group_id=\"\",\n",
        "                page=1\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        ")\n",
        "\n",
        "# NDJSON\n",
        "entities_prediction_ndjson = { \n",
        "    \"name\": \"named_entity\",\n",
        "    # \"confidence\": 0.5,\n",
        "    \"textSelections\": [\n",
        "        {\n",
        "            \"tokenIds\": [\n",
        "                \"<UUID>\",\n",
        "            ],\n",
        "            \"groupId\": \"<UUID>\",\n",
        "            \"page\": 1,\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########### Radio Classification #########\n",
        "\n",
        "# Annotation types \n",
        "radio_prediction = lb_types.ClassificationAnnotation(\n",
        "    name=\"radio_question\",\n",
        "    value=lb_types.Radio(answer = \n",
        "        lb_types.ClassificationAnswer(name = \"first_radio_answer\", confidence=0.5)\n",
        "    )\n",
        ")\n",
        "# NDJSON\n",
        "radio_prediction_ndjson = {\n",
        "  'name': 'radio_question',\n",
        "  'answer': {'name': 'first_radio_answer', \"confidence\": 0.5}\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "############ Checklist Classification ###########\n",
        "\n",
        "# Annotation types \n",
        "checklist_prediction = lb_types.ClassificationAnnotation(\n",
        "    name=\"checklist_question\",\n",
        "    value=lb_types.Checklist(answer = [\n",
        "        lb_types.ClassificationAnswer(name = \"first_checklist_answer\", confidence=0.5),\n",
        "        lb_types.ClassificationAnswer(name = \"second_checklist_answer\", confidence=0.5)\n",
        "    ])\n",
        "  )\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "checklist_prediction_ndjson = {\n",
        "  'name': 'checklist_question',\n",
        "  'answer': [\n",
        "    {'name': 'first_checklist_answer', \"confidence\":0.5},\n",
        "    {'name': 'second_checklist_answer', \"confidence\":0.5}\n",
        "  ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "############ Bounding Box ###########\n",
        "bbox_prediction = lb_types.ObjectAnnotation(\n",
        "    name=\"bounding_box\",  # must match your ontology feature's name\n",
        "    confidence=0.5,\n",
        "    value=lb_types.DocumentRectangle(\n",
        "        start=lb_types.Point(x=86.498, y=42.799),  # x = left, y = top \n",
        "        end=lb_types.Point(x=389.693, y=184.71),  # left + width , y = top + height\n",
        "        page=1,\n",
        "        unit=lb_types.RectangleUnit.POINTS\n",
        "        )\n",
        "    )\n",
        "\n",
        "bbox_prediction_ndjson = {\n",
        "  'name': 'bounding_box',\n",
        "  \"confidence\" : 0.5,\n",
        "  'bbox': {\n",
        "          \"top\": 42.799,\n",
        "          \"left\": 86.498,\n",
        "          \"height\": 141.911,\n",
        "          \"width\": 303.195\n",
        "      },\n",
        "  'page': 0,\n",
        "  'unit': \"POINTS\"\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# ############ nested classifications ###########\n",
        "\n",
        "nested_checklist_prediction_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\", \"confidence\" : 0.5,\n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\", \n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\", \"confidence\": 0.5}\n",
        "        }          \n",
        "      ]         \n",
        "  }]\n",
        "}\n",
        "\n",
        "nested_radio_prediction_ndjson = {\n",
        "  'name': 'nested_radio_question',\n",
        "  'answer': {\n",
        "      'name': 'first_radio_answer', \"confidence\": 0.5,\n",
        "      'classifications': [{\n",
        "          'name':'sub_radio_question',\n",
        "          'answer': { 'name' : 'first_sub_radio_answer', \"confidence\": 0.5}\n",
        "        }]\n",
        "    }\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "############## Classification Free-form text ############## \n",
        "# Confidence scores are not supported for Text classifications \n",
        "\n",
        "text_prediction = lb_types.ClassificationAnnotation(\n",
        "  name=\"free_text\",  # must match your ontology feature's name\n",
        "  value=lb_types.Text(answer=\"sample text\")\n",
        ")\n",
        "\n",
        "\n",
        "text_prediction_ndjson = {\n",
        "  'name': 'free_text',\n",
        "  'answer': 'sample text'\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "############ NER with nested classifications ######## \n",
        "\n",
        "ner_with_checklist_subclass_prediction_ndjson = {\n",
        "  'name': 'ner_with_checklist_subclass',\n",
        "  'classifications':[\n",
        "    {\n",
        "      'name': 'sub_checklist_question', \"confidence\": 0.5,\n",
        "      'answer': [{'name': 'first_sub_checklist_answer', \"confidence\": 0.5}] \n",
        "    }\n",
        "  ],\n",
        "  'textSelections': [\n",
        "      {\n",
        "          \"tokenIds\": [\n",
        "              \"<UUID>\",\n",
        "          ],\n",
        "          \"groupId\": \"<UUID>\",\n",
        "          \"page\": 1,\n",
        "      }\n",
        "  ] \n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######### BBOX with nested classifications #########\n",
        "\n",
        "bbox_with_radio_subclass_prediction = lb_types.ObjectAnnotation(\n",
        "    name=\"bbox_with_radio_subclass\",\n",
        "    confidence=0.5,\n",
        "    value=lb_types.DocumentRectangle(\n",
        "        start=lb_types.Point(x=189.215, y=214.894), # x = left, y = top \n",
        "        end=lb_types.Point(x=429.788, y=478.894), # left + width , y = top + height\n",
        "        unit=\"POINTS\",\n",
        "        page=1\n",
        "    ),\n",
        "    classifications=[\n",
        "    \tlb_types.ClassificationAnnotation(\n",
        "        \tname=\"sub_radio_question\",\n",
        "      \t\tvalue=lb_types.Radio(\n",
        "          answer=lb_types.ClassificationAnswer(\n",
        "            name=\"first_sub_radio_answer\", confidence=0.5,\n",
        "            classifications=[\n",
        "              lb_types.ClassificationAnnotation(\n",
        "                name=\"second_sub_radio_question\",\n",
        "                value=lb_types.Radio(\n",
        "                  answer=lb_types.ClassificationAnswer(\n",
        "                    name=\"second_sub_radio_answer\", confidence=0.5,\n",
        "                  )\n",
        "                )\n",
        "              )\n",
        "            ]\n",
        "          )\n",
        "          )\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "bbox_with_radio_subclass_prediction_ndjson = {\n",
        "  'name': 'bbox_with_radio_subclass',\n",
        "  'classifications': [\n",
        "    {\n",
        "      \"name\": \"sub_radio_question\", \n",
        "      \"answer\": {\n",
        "          \"name\": \"first_sub_radio_answer\", \"confidence\": 0.5,\n",
        "          \"classifications\": [\n",
        "              {\n",
        "                  \"name\": \"second_sub_radio_question\", \n",
        "                  \"answer\": {\n",
        "                      \"name\": \"second_sub_radio_answer\", \"confidence\": 0.5}\n",
        "               }\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "  ],\n",
        "  'bbox': {\n",
        "        \"top\": 214.894,\n",
        "        \"left\": 189.215,\n",
        "        \"height\": 264,\n",
        "        \"width\": 240.573\n",
        "    },\n",
        "  'page': 1,\n",
        "  'unit': \"POINTS\"\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 1: Import data rows into Catalog \n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Text layer url is required for uploading entity annotations\n",
        "global_key = \"0801.3483.pdf\"\n",
        "img_url = {\n",
        "    \"row_data\": {\n",
        "      \"pdf_url\": \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483.pdf\",\n",
        "      \"text_layer_url\": \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483-lb-textlayer.json\"\n",
        "    },\n",
        "    \"global_key\": global_key\n",
        "}\n",
        "\n",
        "\n",
        "dataset = client.create_dataset(name=\"pdf_demo_dataset\")\n",
        "task = dataset.create_data_rows([img_url])\n",
        "task.wait_till_done()\n",
        "print(\"Errors:\",task.errors)\n",
        "print(\"Failed data rows:\", task.failed_data_rows)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There are errors present. Please look at `task.errors` for more details\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: Duplicate global keys found: 0801.3483.pdf\n",
            "Failed data rows: [{'message': 'Duplicate global keys found: 0801.3483.pdf', 'failedDataRows': [{'globalKey': '0801.3483.pdf', 'rowData': 'https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483.pdf', 'attachmentInputs': [], 'mediaAttributes': {'textLayerUrl': 'https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483-lb-textlayer.json'}}]}]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 2: Create/select an Ontology for your project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Setup the ontology and link the tools created above.\n",
        "\n",
        "ontology_builder = lb.OntologyBuilder(\n",
        "  classifications=[ # List of Classification objects\n",
        "    lb.Classification( \n",
        "      class_type=lb.Classification.Type.RADIO,\n",
        "      name=\"radio_question\", \n",
        "      scope = lb.Classification.Scope.GLOBAL,\n",
        "      options=[\n",
        "        lb.Option(value=\"first_radio_answer\"),\n",
        "        lb.Option(value=\"second_radio_answer\")\n",
        "      ]\n",
        "    ),\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.CHECKLIST,\n",
        "      name=\"checklist_question\", \n",
        "      scope = lb.Classification.Scope.GLOBAL,\n",
        "      options=[\n",
        "        lb.Option(value=\"first_checklist_answer\"),\n",
        "        lb.Option(value=\"second_checklist_answer\")\n",
        "      ]\n",
        "    ), \n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.TEXT,\n",
        "      name=\"free_text\",\n",
        "      scope = lb.Classification.Scope.GLOBAL\n",
        "    ),\n",
        "    lb.Classification(\n",
        "        class_type=lb.Classification.Type.RADIO,\n",
        "        name=\"nested_radio_question\",\n",
        "        scope = lb.Classification.Scope.GLOBAL,\n",
        "        options=[\n",
        "            lb.Option(\"first_radio_answer\",\n",
        "                options=[\n",
        "                    lb.Classification(\n",
        "                        class_type=lb.Classification.Type.RADIO,\n",
        "                        name=\"sub_radio_question\",\n",
        "                        options=[lb.Option(\"first_sub_radio_answer\")]\n",
        "                    )\n",
        "                ])\n",
        "          ]\n",
        "    ),\n",
        "    lb.Classification(\n",
        "      class_type=lb.Classification.Type.CHECKLIST,\n",
        "      name=\"nested_checklist_question\",\n",
        "      scope = lb.Classification.Scope.GLOBAL,\n",
        "      options=[\n",
        "          lb.Option(\"first_checklist_answer\",\n",
        "            options=[\n",
        "              lb.Classification(\n",
        "                  class_type=lb.Classification.Type.CHECKLIST,\n",
        "                  name=\"sub_checklist_question\", \n",
        "                  options=[lb.Option(\"first_sub_checklist_answer\")]\n",
        "              )\n",
        "          ])\n",
        "      ]\n",
        "    ),      \n",
        "  ],\n",
        "  tools=[ # List of Tool objects\n",
        "    lb.Tool( tool=lb.Tool.Type.BBOX,name=\"bounding_box\"), \n",
        "    lb.Tool(tool=lb.Tool.Type.NER, name=\"named_entity\"),\n",
        "    lb.Tool(tool=lb.Tool.Type.NER,\n",
        "            name=\"ner_with_checklist_subclass\",\n",
        "            classifications=[\n",
        "              lb.Classification(\n",
        "                class_type=lb.Classification.Type.CHECKLIST,\n",
        "                name=\"sub_checklist_question\",\n",
        "                options=[\n",
        "                  lb.Option(value=\"first_sub_checklist_answer\")\n",
        "                ]\n",
        "              )\n",
        "          ]),\n",
        "    lb.Tool( tool=lb.Tool.Type.BBOX,\n",
        "            name=\"bbox_with_radio_subclass\",\n",
        "            classifications=[\n",
        "              lb.Classification(\n",
        "                  class_type=lb.Classification.Type.RADIO,\n",
        "                  name=\"sub_radio_question\",\n",
        "                  options=[\n",
        "                    lb.Option(\n",
        "                      value=\"first_sub_radio_answer\" ,\n",
        "                      options=[\n",
        "                        lb.Classification(\n",
        "                          class_type=lb.Classification.Type.RADIO,\n",
        "                          name='second_sub_radio_question',\n",
        "                          options=[lb.Option(\"second_sub_radio_answer\")]\n",
        "                        )]\n",
        "                    )]\n",
        "                )]\n",
        "      )]\n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\"Document Annotation Import Demo\",\n",
        "                                  ontology_builder.asdict(),\n",
        "                                  media_type=lb.MediaType.Document)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 3: Create a Model and Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# create Model\n",
        "model = client.create_model(name=\"pdf_model_run_\" + str(uuid.uuid4()),\n",
        "                            ontology_id=ontology.uid)\n",
        "# create Model Run\n",
        "model_run = model.create_model_run(\"iteration 1\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 4: Send data rows to the Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "model_run.upsert_data_rows(global_keys=[global_key])"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 5: Create the predictions payload\n",
        "Create the prediction payload using the snippets of code in ***Supported Predictions*** section. \n",
        "\n",
        "The resulting label_ndjson should have exactly the same content for predictions that are supported by both"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "First, populate the text selections in the entity predictions."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Helper method\n",
        "def update_text_selections(annotation, group_id, list_tokens, page):\n",
        "  return annotation.update({\n",
        "    'textSelections': [\n",
        "      {\n",
        "        'groupId': group_id,\n",
        "        'tokenIds': list_tokens,\n",
        "        'page': page\n",
        "      }\n",
        "    ]\n",
        "  })\n",
        "  \n",
        "\n",
        "text_layer = \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483-lb-textlayer.json\"\n",
        "\n",
        "# Fetch the content of the text layer\n",
        "res = requests.get(text_layer) \n",
        "\n",
        "\n",
        "# Phrases that we want to annotation obtained from the text layer url\n",
        "content_phrases = [\"Metal-insulator (MI) transitions have been one of the\" , \n",
        "                   \"T. Sasaki,* N. Yoneyama, and N. Kobayashi\", \n",
        "                   \"Organic charge transfer salts based on the donor\",\n",
        "                   \"the experimental investigations on this issue have not\"]\n",
        "\n",
        "# Parse the text layer\n",
        "text_selections = []\n",
        "text_selections_source = []\n",
        "text_selections_target = []\n",
        "\n",
        "for obj in json.loads(res.text):\n",
        "  for group in obj['groups']:\n",
        "    if group['content'] == content_phrases[0]:\n",
        "      list_tokens = [x['id'] for x in group['tokens']]\n",
        "      # build text selections for Python Annotation Types\n",
        "      document_text_selection = lb_types.DocumentTextSelection(groupId=group['id'], tokenIds=list_tokens, page=1)\n",
        "      text_selections.append(document_text_selection)\n",
        "      # build text selection for the NDJson annotations\n",
        "      update_text_selections(annotation=entities_prediction_ndjson,\n",
        "                             group_id=group['id'], # id representing group of words \n",
        "                             list_tokens=list_tokens, # ids representing individual words from the group\n",
        "                             page=1)\n",
        "    if group['content'] == content_phrases[1]:\n",
        "      list_tokens_2 = [x['id'] for x in group['tokens']]\n",
        "      update_text_selections(annotation=ner_with_checklist_subclass_prediction_ndjson,\n",
        "                             group_id=group['id'], # id representing group of words \n",
        "                             list_tokens=list_tokens_2, # ids representing individual words from the group\n",
        "                             page=1)\n",
        "   \n",
        "\n",
        "    \n",
        "      \n",
        "#re-write the entity annotation with text selections (python annotation types)\n",
        "entities_prediction_document_entity = lb_types.DocumentEntity(name=\"named_entity\", \n",
        "                                          textSelections = text_selections)\n",
        "entities_prediction = lb_types.ObjectAnnotation(name=\"named_entity\",\n",
        "                                                value=entities_prediction_document_entity)\n",
        "\n",
        "\n",
        "        \n",
        "print(f\"entities_prediction_ndjson={entities_prediction_ndjson}\")\n",
        "print(f\"entities_prediction={entities_prediction}\")\n",
        "print(f\"nested_entities_annotation={ner_with_checklist_subclass_prediction_ndjson}\")\n"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "entities_prediction_ndjson={'name': 'named_entity', 'confidence': 0.5, 'textSelections': [{'groupId': '2f4336f4-a07e-4e0a-a9e1-5629b03b719b', 'tokenIds': ['3f984bf3-1d61-44f5-b59a-9658a2e3440f', '3bf00b56-ff12-4e52-8cc1-08dbddb3c3b8', '6e1c3420-d4b7-4c5a-8fd6-ead43bf73d80', '87a43d32-af76-4a1d-b262-5c5f4d5ace3a', 'e8606e8a-dfd9-4c49-a635-ad5c879c75d0', '67c7c19e-4654-425d-bf17-2adb8cf02c30', '149c5e80-3e07-49a7-ab2d-29ddfe6a38fa', 'b0e94071-2187-461e-8e76-96c58738a52c'], 'page': 1}], 'dataRow': {'globalKey': '0801.3483.pdf'}}\n",
            "entities_prediction=confidence=None name='named_entity' feature_schema_id=None extra={} value=DocumentEntity(text_selections=[DocumentTextSelection(token_ids=['3f984bf3-1d61-44f5-b59a-9658a2e3440f', '3bf00b56-ff12-4e52-8cc1-08dbddb3c3b8', '6e1c3420-d4b7-4c5a-8fd6-ead43bf73d80', '87a43d32-af76-4a1d-b262-5c5f4d5ace3a', 'e8606e8a-dfd9-4c49-a635-ad5c879c75d0', '67c7c19e-4654-425d-bf17-2adb8cf02c30', '149c5e80-3e07-49a7-ab2d-29ddfe6a38fa', 'b0e94071-2187-461e-8e76-96c58738a52c'], group_id='2f4336f4-a07e-4e0a-a9e1-5629b03b719b', page=1)]) classifications=[]\n",
            "nested_entities_annotation={'name': 'ner_with_checklist_subclass', 'classifications': [{'name': 'sub_checklist_question', 'confidence': 0.5, 'answer': [{'name': 'first_sub_checklist_answer', 'confidence': 0.5}]}], 'textSelections': [{'groupId': '80e1e326-0194-4f38-845c-d9d22b0054fb', 'tokenIds': ['c2639311-4db1-4ad5-9a8d-1f2ab2c2dae8', '2aa2f9df-df5a-4b3a-aa57-05aff053c147', 'aa725467-7b86-4629-9c70-a6391decb39b', '6a4a0a69-f04e-44c0-b343-096aef413444', '8dcce11c-c2ae-4274-b634-c950c8a7f333', '85fccf77-474b-4707-85cc-592871d5c680', '5d16be99-fc40-4228-99db-0a121a0478e7'], 'page': 1}]}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Create a Label for predictions\n",
        "label = []\n",
        "label.append(lb_types.Label(\n",
        "    data=lb_types.DocumentData(global_key=global_key),\n",
        "    annotations = [\n",
        "      entities_prediction,\n",
        "      radio_prediction,\n",
        "      checklist_prediction, \n",
        "      bbox_prediction, \n",
        "      bbox_with_radio_subclass_prediction \n",
        "      ]\n",
        "  )\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "If using NDJSON"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "label_prediction_ndjson = []\n",
        "\n",
        "for annot in [\n",
        "    entities_prediction_ndjson,\n",
        "    radio_prediction_ndjson,\n",
        "    checklist_prediction_ndjson, \n",
        "    bbox_prediction_ndjson, \n",
        "    bbox_with_radio_subclass_prediction_ndjson, \n",
        "    nested_radio_prediction_ndjson,\n",
        "    nested_checklist_prediction_ndjson\n",
        "]:\n",
        "  annot.update({\n",
        "      'uuid': str(uuid.uuid4()),\n",
        "      'dataRow': {'globalKey': global_key}\n",
        "  })\n",
        "  label_prediction_ndjson.append(annot)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 6: Upload the predictions payload to the Model Run"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Upload the prediction label to the Model Run\n",
        "upload_job_prediction = model_run.add_predictions(\n",
        "    name=\"prediction_upload_job\"+str(uuid.uuid4()),\n",
        "    predictions=label_prediction_ndjson)\n",
        "\n",
        "# Errors will appear for prediction uploads that failed.\n",
        "print(\"Errors:\",  upload_job_prediction.errors)\n",
        "print(\"Status of uploads: \", upload_job_prediction.statuses)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: [{'uuid': '20859877-8c68-4df8-a3d1-4bcc8da38326', 'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'}, 'status': 'FAILURE', 'errors': [{'name': 'ValidationError', 'message': \"{'_schema': ['Confidence is not supported for this type of annotation']}\", 'additionalInfo': None}]}, {'uuid': '6d4963f2-5d0e-48e0-a6c0-7e7dd1b08329', 'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'}, 'status': 'FAILURE', 'errors': [{'name': 'ValidationError', 'message': \"{'_schema': ['Confidence is not supported for this type of annotation']}\", 'additionalInfo': None}]}, {'uuid': 'b923e24d-6c30-41b4-a1b9-e61a9460585e', 'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'}, 'status': 'FAILURE', 'errors': [{'name': 'ValidationError', 'message': \"{'_schema': ['Confidence is not supported for this type of annotation']}\", 'additionalInfo': None}]}]\n",
            "Status of uploads:  [{'uuid': '20859877-8c68-4df8-a3d1-4bcc8da38326', 'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'}, 'status': 'FAILURE', 'errors': [{'name': 'ValidationError', 'message': \"{'_schema': ['Confidence is not supported for this type of annotation']}\", 'additionalInfo': None}]}, {'uuid': '30033980-9eeb-48eb-9665-259bf66f41a6', 'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'}, 'status': 'SUCCESS'}, {'uuid': '83d91a66-19d1-4802-be84-3ca5cefa0ed9', 'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'}, 'status': 'SUCCESS'}, {'uuid': '6d4963f2-5d0e-48e0-a6c0-7e7dd1b08329', 'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'}, 'status': 'FAILURE', 'errors': [{'name': 'ValidationError', 'message': \"{'_schema': ['Confidence is not supported for this type of annotation']}\", 'additionalInfo': None}]}, {'uuid': 'b923e24d-6c30-41b4-a1b9-e61a9460585e', 'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'}, 'status': 'FAILURE', 'errors': [{'name': 'ValidationError', 'message': \"{'_schema': ['Confidence is not supported for this type of annotation']}\", 'additionalInfo': None}]}, {'uuid': '00499327-10b3-466d-ba59-b0466f5db468', 'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'}, 'status': 'SUCCESS'}, {'uuid': '5893c8ce-b36e-4692-b82b-67025bb1dc98', 'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'}, 'status': 'SUCCESS'}]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "status_output = upload_job_prediction.statuses\n",
        "status_output"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'uuid': '20859877-8c68-4df8-a3d1-4bcc8da38326',\n",
              "  'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'},\n",
              "  'status': 'FAILURE',\n",
              "  'errors': [{'name': 'ValidationError',\n",
              "    'message': \"{'_schema': ['Confidence is not supported for this type of annotation']}\",\n",
              "    'additionalInfo': None}]},\n",
              " {'uuid': '30033980-9eeb-48eb-9665-259bf66f41a6',\n",
              "  'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'},\n",
              "  'status': 'SUCCESS'},\n",
              " {'uuid': '83d91a66-19d1-4802-be84-3ca5cefa0ed9',\n",
              "  'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'},\n",
              "  'status': 'SUCCESS'},\n",
              " {'uuid': '6d4963f2-5d0e-48e0-a6c0-7e7dd1b08329',\n",
              "  'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'},\n",
              "  'status': 'FAILURE',\n",
              "  'errors': [{'name': 'ValidationError',\n",
              "    'message': \"{'_schema': ['Confidence is not supported for this type of annotation']}\",\n",
              "    'additionalInfo': None}]},\n",
              " {'uuid': 'b923e24d-6c30-41b4-a1b9-e61a9460585e',\n",
              "  'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'},\n",
              "  'status': 'FAILURE',\n",
              "  'errors': [{'name': 'ValidationError',\n",
              "    'message': \"{'_schema': ['Confidence is not supported for this type of annotation']}\",\n",
              "    'additionalInfo': None}]},\n",
              " {'uuid': '00499327-10b3-466d-ba59-b0466f5db468',\n",
              "  'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'},\n",
              "  'status': 'SUCCESS'},\n",
              " {'uuid': '5893c8ce-b36e-4692-b82b-67025bb1dc98',\n",
              "  'dataRow': {'id': 'clfh1n29e1mh2078d3jt3b5cx', 'globalKey': '0801.3483.pdf'},\n",
              "  'status': 'SUCCESS'}]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "errors_job = [i['uuid'] for i in status_output if i['status'] == 'FAILURE']\n",
        "errors_job"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['20859877-8c68-4df8-a3d1-4bcc8da38326',\n",
              " '6d4963f2-5d0e-48e0-a6c0-7e7dd1b08329',\n",
              " 'b923e24d-6c30-41b4-a1b9-e61a9460585e']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "errors_ndjson = [i for i in label_prediction_ndjson if i['uuid'] in errors_job]\n",
        "errors_ndjson"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'named_entity',\n",
              "  'confidence': 0.5,\n",
              "  'textSelections': [{'groupId': '2f4336f4-a07e-4e0a-a9e1-5629b03b719b',\n",
              "    'tokenIds': ['3f984bf3-1d61-44f5-b59a-9658a2e3440f',\n",
              "     '3bf00b56-ff12-4e52-8cc1-08dbddb3c3b8',\n",
              "     '6e1c3420-d4b7-4c5a-8fd6-ead43bf73d80',\n",
              "     '87a43d32-af76-4a1d-b262-5c5f4d5ace3a',\n",
              "     'e8606e8a-dfd9-4c49-a635-ad5c879c75d0',\n",
              "     '67c7c19e-4654-425d-bf17-2adb8cf02c30',\n",
              "     '149c5e80-3e07-49a7-ab2d-29ddfe6a38fa',\n",
              "     'b0e94071-2187-461e-8e76-96c58738a52c'],\n",
              "    'page': 1}],\n",
              "  'dataRow': {'globalKey': '0801.3483.pdf'},\n",
              "  'uuid': '20859877-8c68-4df8-a3d1-4bcc8da38326'},\n",
              " {'name': 'bounding_box',\n",
              "  'confidence': 0.5,\n",
              "  'bbox': {'top': 42.799, 'left': 86.498, 'height': 141.911, 'width': 303.195},\n",
              "  'page': 0,\n",
              "  'unit': 'POINTS',\n",
              "  'dataRow': {'globalKey': '0801.3483.pdf'},\n",
              "  'uuid': '6d4963f2-5d0e-48e0-a6c0-7e7dd1b08329'},\n",
              " {'name': 'bbox_with_radio_subclass',\n",
              "  'classifications': [{'name': 'sub_radio_question',\n",
              "    'answer': {'name': 'first_sub_radio_answer',\n",
              "     'confidence': 0.5,\n",
              "     'classifications': [{'name': 'second_sub_radio_question',\n",
              "       'answer': {'name': 'second_sub_radio_answer', 'confidence': 0.5}}]}}],\n",
              "  'bbox': {'top': 214.894, 'left': 189.215, 'height': 264, 'width': 240.573},\n",
              "  'page': 1,\n",
              "  'unit': 'POINTS',\n",
              "  'dataRow': {'globalKey': '0801.3483.pdf'},\n",
              "  'uuid': 'b923e24d-6c30-41b4-a1b9-e61a9460585e'}]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Step 7: Send annotations to a model run \n",
        "To visualize both annotations and predictions in the model run we will create a project with ground truth annotations. \n",
        "To send annotations to a Model Run, we must first import them into a project, create a label payload and then send them to the Model Run."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "##### 7.1 Create a labelbox project "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create a Labelbox project\n",
        "project = client.create_project(name=\"pdf_prediction_demo\",\n",
        "                                    auto_audit_percentage=1,\n",
        "                                    auto_audit_number_of_labels=1,\n",
        "                                    media_type=lb.MediaType.Image)\n",
        "project.setup_editor(ontology)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.2 Create a batch to send to the project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "project.create_batch(\n",
        "  \"batch_predictions_demo\", # Each batch in a project must have a unique name\n",
        "  global_keys=[global_key], # Paginated collection of data row objects, list of data row ids or global keys\n",
        "  priority=5 # priority between 1(Highest) - 5(lowest)\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### 7.3 Create the annotations payload"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Create a Labelbox project\n",
        "project = client.create_project(name=\"PDF_annotation_demo\",                                    \n",
        "                                    queue_mode=QueueMode.Batch,\n",
        "                                    media_type=lb.MediaType.Document)\n",
        "project.setup_editor(ontology)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "#### Step 4: Send a batch of data rows to the project "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "project.create_batch(\n",
        "  \"PDF_annotation_batch\", # Each batch in a project must have a unique name\n",
        "  global_keys=[global_key], # Paginated collection of data row objects, list of data row ids or global keys\n",
        "  priority=5 # priority between 1(Highest) - 5(lowest)\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 5: Create the annotation payload \n",
        "Create the annotations payload using the snippets of code in Supported predictions section.\n",
        "\n",
        "Labelbox support NDJSON only for this data type.\n",
        "\n",
        "The resulting label should have exactly the same content for annotations that are supported by both (with exception of the uuid strings that are generated)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "First, we need to populate the text selections for Entity annotations\n",
        "\n",
        "To learn how to generate a text layer for your documents please refer to the following repositories/files:   https://github.com/Labelbox/PDF-OCR-Transform-CLI/blob/main/src/scripts/gcloud/gcp-vision-to-lb-text-layer.py  https://github.com/Labelbox/PDF-OCR-Transform-CLI/blob/main/src/scripts/adobe/adobe-ocr-to-lb-text-layer.py "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Helper method\n",
        "def update_text_selections(annotation, group_id, list_tokens, page):\n",
        "  return annotation.update({\n",
        "    'textSelections': [\n",
        "      {\n",
        "        'groupId': group_id,\n",
        "        'tokenIds': list_tokens,\n",
        "        'page': page\n",
        "      }\n",
        "    ]\n",
        "  })\n",
        "  \n",
        "\n",
        "text_layer = \"https://storage.googleapis.com/labelbox-datasets/arxiv-pdf/data/99-word-token-pdfs/0801.3483-lb-textlayer.json\"\n",
        "\n",
        "# Fetch the content of the text layer\n",
        "res = requests.get(text_layer) \n",
        "\n",
        "\n",
        "# Phrases that we want to annotation obtained from the text layer url\n",
        "content_phrases = [\"Metal-insulator (MI) transitions have been one of the\" , \n",
        "                   \"T. Sasaki,* N. Yoneyama, and N. Kobayashi\", \n",
        "                   \"Organic charge transfer salts based on the donor\",\n",
        "                   \"the experimental investigations on this issue have not\"]\n",
        "\n",
        "# Parse the text layer\n",
        "text_selections = []\n",
        "text_selections_source = []\n",
        "text_selections_target = []\n",
        "\n",
        "for obj in json.loads(res.text):\n",
        "  for group in obj['groups']:\n",
        "    if group['content'] == content_phrases[0]:\n",
        "      list_tokens = [x['id'] for x in group['tokens']]\n",
        "      # build text selections for Python Annotation Types\n",
        "      document_text_selection = lb_types.DocumentTextSelection(groupId=group['id'], tokenIds=list_tokens, page=1)\n",
        "      text_selections.append(document_text_selection)\n",
        "      # build text selection for the NDJson annotations\n",
        "      update_text_selections(annotation=entities_prediction_ndjson,\n",
        "                             group_id=group['id'], # id representing group of words \n",
        "                             list_tokens=list_tokens, # ids representing individual words from the group\n",
        "                             page=1)\n",
        "    if group['content'] == content_phrases[1]:\n",
        "      list_tokens_2 = [x['id'] for x in group['tokens']]\n",
        "      update_text_selections(annotation=ner_with_checklist_subclass_prediction_ndjson,\n",
        "                             group_id=group['id'], # id representing group of words \n",
        "                             list_tokens=list_tokens_2, # ids representing individual words from the group\n",
        "                             page=1)\n",
        "   \n",
        "\n",
        "    \n",
        "      \n",
        "#re-write the entity annotation with text selections (python annotation types)\n",
        "entities_annotation_document_entity = lb_types.DocumentEntity(name=\"named_entity\", \n",
        "                                          textSelections = text_selections)\n",
        "entities_annotation = lb_types.ObjectAnnotation(name=\"named_entity\",\n",
        "                                                value=entities_annotation_document_entity)\n",
        "\n",
        "\n",
        "        \n",
        "print(f\"entities_annotations_ndjson={entities_prediction_ndjson}\")\n",
        "print(f\"entities_annotation={entities_annotation}\")\n",
        "print(f\"nested_entities_annotation={ner_with_checklist_subclass_prediction_ndjson}\")\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "Python annotation\n",
        "\n",
        "Here we create the complete labels ndjson payload of annotations only using python annotation format. There is one annotation for each reference to an annotation that we created. Note that only a handful of python annotation types are supported for PDF documents."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "python_labels = []\n",
        "\n",
        "python_labels.append(\n",
        "    lb_types.Label(\n",
        "        data=lb_types.DocumentData(\n",
        "            global_key=global_key),\n",
        "        annotations = [\n",
        "            entities_annotation,\n",
        "            checklist_annotation, \n",
        "            text_annotation,\n",
        "            radio_annotation,\n",
        "            bbox_annotation,\n",
        "            bbox_with_radio_subclass_annotation,\n",
        "            bbox_source,\n",
        "            bbox_target,\n",
        "            bbox_relationship, \n",
        "            entity_source, \n",
        "            entity_target, \n",
        "            entity_relationship\n",
        "        ]\n",
        "  )\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}