{
  "nbformat": 4,
  "nbformat_minor": 1,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=190/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/basics/getting_started.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/basics/getting_started.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Getting started\n",
        "\n",
        "This notebook is intended to provide an example of getting started with the Labelbox SDK."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install \"labelbox[data]\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import labelbox.types as lb_types\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from uuid import uuid4\n",
        "import datetime\n",
        "import random"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Setup Labelbox Client "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Generate API key: https://app.labelbox.com/account/api-keys\n",
        "LB_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjbG9vcmRpaGUwMDkyMDcza2Nvcm5jajdnIiwib3JnYW5pemF0aW9uSWQiOiJjbG9vcmRpZ3cwMDkxMDcza2M2cG9oeWFiIiwiYXBpS2V5SWQiOiJjbHE1OWd6M3MwMDRxMDcweDRwb3BmajV4Iiwic2VjcmV0IjoiOWE5ZWVmNDczNDI2ZDI2ZjUwOTU5ZDY4ZmZiNGJmMWMiLCJpYXQiOjE3MDI1NjIwMjYsImV4cCI6MjMzMzcxNDAyNn0.BsdKnIr8Np4eYxJ_6VILmuY-D6n2gUdvGKGvMHq9Eh4\"\n",
        "client = lb.Client(LB_API_KEY)\n",
        "\n",
        "DATA_ROWS = \"https://storage.googleapis.com/labelbox-datasets/VHR_geospatial/geospatial_datarows.json\"\n",
        "ANNOTATIONS = \"https://storage.googleapis.com/labelbox-datasets/VHR_geospatial/geospatial_annotations.json\""
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        " ## Importing a labeled dataset"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## Generic data download function\n",
        "def download_files(filemap):\n",
        "    path, uri = filemap    \n",
        "    ## Download data\n",
        "    if not os.path.exists(path):\n",
        "        r = requests.get(uri, stream=True)\n",
        "        if r.status_code == 200:\n",
        "            with open(path, 'wb') as f:\n",
        "                for chunk in r:\n",
        "                    f.write(chunk)\n",
        "    return path"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Download a public dataset"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "download_files((\"data_rows.json\", DATA_ROWS))\n",
        "download_files((\"annotations.json\", ANNOTATIONS))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "with open('data_rows.json', 'r') as fp:\n",
        "    data_rows = json.load(fp)\n",
        "\n",
        "with open('annotations.json', 'r') as fp:\n",
        "    annotations = json.load(fp)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Create a dataset"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "dataset = client.create_dataset(name=\"Geospatial vessel detection\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Import Data Rows with Metadata"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Here is an example of adding two metadata fields to your Data Rows: a \"captureDateTime\" field with datetime value, and a \"tag\" field with string value\n",
        "metadata_ontology = client.get_data_row_metadata_ontology()\n",
        "datetime_schema_id = metadata_ontology.reserved_by_name[\"captureDateTime\"].uid\n",
        "tag_schema_id = metadata_ontology.reserved_by_name[\"tag\"].uid\n",
        "tag_items = [\"WorldView-1\", \"WorldView-2\", \"WorldView-3\", \"WorldView-4\"]\n",
        "\n",
        "for datarow in data_rows:\n",
        "    dt = datetime.datetime.utcnow() + datetime.timedelta(days=random.random()*30) # this is random datetime value\n",
        "    tag_item = random.choice(tag_items) # this is a random tag value\n",
        "\n",
        "    # Option 1: Specify metadata with a list of DataRowMetadataField. This is the recommended option since it comes with validation for metadata fields.\n",
        "    metadata_fields = [\n",
        "                       lb.DataRowMetadataField(schema_id=datetime_schema_id, value=dt), \n",
        "                       lb.DataRowMetadataField(schema_id=tag_schema_id, value=tag_item)\n",
        "                       ]\n",
        "\n",
        "    # Option 2: Uncomment to try. Alternatively, you can specify the metadata fields with dictionary format without declaring the DataRowMetadataField objects. It is equivalent to Option 1.\n",
        "    # metadata_fields = [\n",
        "    #                    {\"schema_id\": datetime_schema_id, \"value\": dt}, \n",
        "    #                    {\"schema_id\": tag_schema_id, \"value\": tag_item}\n",
        "    #                    ]\n",
        "\n",
        "    datarow[\"metadata_fields\"] = metadata_fields"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "task = dataset.create_data_rows(data_rows)\n",
        "task.wait_till_done()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "#### Examine a Data Row"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "datarow = next(dataset.data_rows())\n",
        "print(datarow)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# Setup a labeling project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "ontology = lb.OntologyBuilder()\n",
        "\n",
        "for tool in annotations['categories']:\n",
        "  print(tool['name'])\n",
        "  ontology.add_tool(lb.Tool(tool = lb.Tool.Type.BBOX, name = tool['name']))\n",
        "\n",
        "ontology = client.create_ontology(\"Vessel detection ontology\", ontology.asdict())\n",
        "project = client.create_project(name=\"Vessel detection\", media_type=lb.MediaType.Image)\n",
        "project.setup_editor(ontology)\n",
        "ontology_from_project = lb.OntologyBuilder.from_project(project)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Prepare and queue batch of Data Rows to the project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "#### Export Dataset"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "client.enable_experimental = True\n",
        "\n",
        "export_task = dataset.export()\n",
        "export_task.wait_till_done()"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "#### Stream Data Rows"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "data_rows_ids = []\n",
        "\n",
        "def json_stream_handler(output: lb.JsonConverterOutput):\n",
        "  data_row = json.loads(output.json_str)\n",
        "  data_rows_ids.append(data_row[\"data_row\"][\"id\"])\n",
        "\n",
        "\n",
        "if export_task.has_errors():\n",
        "  export_task.get_stream(\n",
        "  converter=lb.JsonConverter(),\n",
        "  stream_type=lb.StreamType.ERRORS\n",
        "  ).start(stream_handler=lambda error: print(error))\n",
        "\n",
        "if export_task.has_result():\n",
        "  export_json = export_task.get_stream(\n",
        "    converter=lb.JsonConverter(),\n",
        "    stream_type=lb.StreamType.RESULT\n",
        "  ).start(stream_handler=json_stream_handler)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "#### Create Batch for Project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Randomly select 200 Data Rows\n",
        "sampled_data_rows = random.sample(data_rows_ids, 200)\n",
        "\n",
        "batch = project.create_batch(\n",
        "  f\"Batch-{str(uuid4())}\", # name of the batch\n",
        "  sampled_data_rows, # list of Data Rows\n",
        "  1 # priority between 1-5\n",
        ")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Process ground truth annotations for import"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "queued_data_rows = project.export_queued_data_rows()\n",
        "ground_truth_list = list()\n",
        "\n",
        "for datarow in queued_data_rows:\n",
        "  annotations_list = []\n",
        "  folder = datarow['externalId'].split(\"/\")[0]\n",
        "  id = datarow['externalId'].split(\"/\")[1]\n",
        "  if folder == \"positive_image_set\":\n",
        "    for image in annotations['images']:\n",
        "      if (image['file_name']==id):\n",
        "        for annotation in annotations['annotations']:\n",
        "          if annotation['image_id'] == image['id']:\n",
        "            bbox = annotation['bbox']\n",
        "            id = annotation['category_id'] - 1\n",
        "            class_name = ontology_from_project.tools[id].name\n",
        "            annotations_list.append(lb_types.ObjectAnnotation(\n",
        "                name = class_name,\n",
        "                value = lb_types.Rectangle(start = lb_types.Point(x = bbox[0], y = bbox[1]), end = lb_types.Point(x = bbox[2]+bbox[0], y = bbox[3]+bbox[1])),\n",
        "            ))\n",
        "  image = lb_types.ImageData(uid = datarow['id'])\n",
        "  ground_truth_list.append(lb_types.Label(data = image, annotations = annotations_list))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Import ground truth annotation"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "start_time = time.time()\n",
        "## Upload annotations\n",
        "upload_task = lb.LabelImport.create_from_objects(client, project.uid, \"geospatial-import-job-1\", ground_truth_list)\n",
        "print(upload_task)\n",
        "\n",
        "#Wait for upload to finish (Will take up to five minutes)\n",
        "upload_task.wait_until_done()\n",
        "print(upload_task.errors)\n",
        "print(\"--- Finished in %s mins ---\" % ((time.time() - start_time)/60))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}