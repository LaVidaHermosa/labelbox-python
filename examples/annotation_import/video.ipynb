{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://labelbox.com\" ><img src=\"https://labelbox.com/blog/content/images/2021/02/logo-v4.svg\" width=256/></a>\n",
        "</td>"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "<td>\n",
        "<a href=\"https://colab.research.google.com/github/Labelbox/labelbox-python/blob/master/examples/annotation_import/video.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "</td>\n",
        "\n",
        "<td>\n",
        "\n",
        "<a href=\"https://github.com/Labelbox/labelbox-python/tree/master/examples/annotation_import/video.ipynb\" target=\"_blank\"><img\n",
        "src=\"https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white\" alt=\"GitHub\"></a>\n",
        "</td> "
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Video Annotation Import\n",
        "\n",
        "* Annotations must be created and uploaded using NDJSON\n",
        "* Supported annotations that can be uploaded through the SDK:\n",
        "    * Bounding box\n",
        "    * Point\n",
        "    * Polyline \n",
        "    * Radio classifications \n",
        "    * Checklist classifications \n",
        "* **NOT** supported:\n",
        "    * Polygons \n",
        "    * Segmentation masks\n",
        "    * Free form text classifications\n",
        "\n",
        "Please note that this list of unsupported annotations only refers to limitations for importing annotations. For example, when using the Labelbox editor, segmentation masks can be created and edited on video assets."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Setup"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "!pip install -q 'labelbox[data]'"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "import labelbox as lb\n",
        "import labelbox.types as lb_types\n",
        "import uuid"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Replace with your API key \n",
        "Guides on [Create an API key](https://docs.labelbox.com/docs/create-an-api-key)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Add your api key\n",
        "API_KEY=\"\"\n",
        "client = lb.Client(api_key=API_KEY)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Supported annotations for video\n"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "######## Bounding box  ###########\n",
        "# Python Annotation \n",
        "bbox_annotation = [\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_video\",  \n",
        "    keyframe=True,\n",
        "    frame=13,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=146.0, y=98.0), # Top left\n",
        "          end=lb_types.Point(x=382.0, y=341.0), # Bottom right\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_video\",  \n",
        "    keyframe=True,\n",
        "    frame=15,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=146.0, y=98.0), # Top left\n",
        "          end=lb_types.Point(x=382.0, y=341.0), # Bottom right\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"bbox_video\",  \n",
        "    keyframe=True,\n",
        "    frame=19,\n",
        "    segment_index=0,\n",
        "    value = lb_types.Rectangle(\n",
        "          start=lb_types.Point(x=146.0, y=98.0), # Top left\n",
        "          end=lb_types.Point(x=382.0, y=341.0), # Bottom right\n",
        "      )\n",
        "  )\n",
        "]\n",
        "\n",
        "\n",
        "# NDJSON\n",
        "bbox_annotation_ndjson = {\n",
        "    \"name\" : \"bbox_video\",\n",
        "    \"segments\" : [{\n",
        "        \"keyframes\" : [\n",
        "            {\n",
        "              \"frame\": 13,\n",
        "              \"bbox\" : {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              }  \n",
        "           },\n",
        "           {\n",
        "              \"frame\": 15,\n",
        "              \"bbox\" : {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              }  \n",
        "           },\n",
        "           {\n",
        "              \"frame\": 19,\n",
        "              \"bbox\" : {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              }  \n",
        "           }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######## Point ########\n",
        "\n",
        "point_annotation = [\n",
        "    lb_types.VideoObjectAnnotation(\n",
        "        name = \"point_video\",\n",
        "        keyframe=True,\n",
        "        frame=17,\n",
        "        value = lb_types.Point(x=660.134, y=407.926),\n",
        "        )\n",
        "]\n",
        "\n",
        "#NDJSON\n",
        "point_annotation_ndjson = {\n",
        "    \"name\": \"point_video\", \n",
        "    \"segments\": [{\n",
        "        \"keyframes\": [{\n",
        "            \"frame\": 17,\n",
        "            \"point\" : {\n",
        "                \"x\": 660.134 ,\n",
        "                \"y\": 407.926\n",
        "            }\n",
        "        }]\n",
        "    }] \n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######## Polyline ########\n",
        "polyline_annotation = [\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=5,\n",
        "    segment_index=0,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=12,\n",
        "    segment_index=0,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=20,\n",
        "    segment_index=0,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=24,\n",
        "    segment_index=1,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  ),\n",
        "  lb_types.VideoObjectAnnotation(\n",
        "    name = \"line_video_frame\",\n",
        "    keyframe=True, \n",
        "    frame=45,\n",
        "    segment_index=1,\n",
        "    value=lb_types.Line( \n",
        "          points=[lb_types.Point(x=680, y=100), lb_types.Point(x=100, y=190)]\n",
        "      )\n",
        "  )\n",
        "  \n",
        "]\n",
        "\n",
        "\n",
        "polyline_frame_annotation_ndjson = {\n",
        "  \"name\": \"line_video_frame\", \n",
        "  \"segments\": [\n",
        "      {\n",
        "        \"keyframes\": [\n",
        "          {\n",
        "            \"frame\": 5,\n",
        "            \"line\": [{\n",
        "              \"x\": 680,\n",
        "              \"y\": 100\n",
        "            },{\n",
        "              \"x\": 100,\n",
        "              \"y\": 190\n",
        "            },{\n",
        "              \"x\": 190,\n",
        "              \"y\": 220\n",
        "            }]\n",
        "          },\n",
        "          {\n",
        "            \"frame\": 12,\n",
        "            \"line\": [{\n",
        "              \"x\": 680,\n",
        "              \"y\": 280\n",
        "            },{\n",
        "              \"x\": 300,\n",
        "              \"y\": 380\n",
        "            },{\n",
        "              \"x\": 400,\n",
        "              \"y\": 460\n",
        "            }]\n",
        "          },\n",
        "          {\n",
        "            \"frame\": 20,\n",
        "            \"line\": [{\n",
        "              \"x\": 680,\n",
        "              \"y\": 180\n",
        "            },{\n",
        "              \"x\": 100,\n",
        "              \"y\": 200\n",
        "            },{\n",
        "              \"x\": 200,\n",
        "              \"y\": 260\n",
        "            }]\n",
        "          }\n",
        "        ]\n",
        "      },\n",
        "      {\n",
        "        \"keyframes\": [\n",
        "          {\n",
        "            \"frame\": 24,\n",
        "            \"line\": [{\n",
        "              \"x\": 300,\n",
        "              \"y\": 310\n",
        "            },{\n",
        "              \"x\": 330,\n",
        "              \"y\": 430\n",
        "            }]\n",
        "          },\n",
        "          {\n",
        "            \"frame\": 45,\n",
        "            \"line\": [{\n",
        "              \"x\": 600,\n",
        "              \"y\": 810\n",
        "            },{\n",
        "              \"x\": 900,\n",
        "              \"y\": 930\n",
        "            }]\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "######## Frame base classifications ########\n",
        "\n",
        "\n",
        "radio_annotation = [\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"radio_class\", \n",
        "        frame=9,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Radio(answer = lb_types.ClassificationAnswer(name = \"first_radio_answer\"))\n",
        "    ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"radio_class\", \n",
        "        frame=15,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Radio(answer = lb_types.ClassificationAnswer(name = \"first_radio_answer\"))\n",
        "    )\n",
        "]\n",
        "\n",
        "checklist_annotation= [\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\",\n",
        "        frame=29,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"first_checklist_answer\"\n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\", \n",
        "        frame=35,\n",
        "        segment_index=0,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"first_checklist_answer\"\n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\", \n",
        "        frame=39, \n",
        "        segment_index=1,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"second_checklist_answer\"\n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        ),\n",
        "    lb_types.VideoClassificationAnnotation(\n",
        "        name=\"checklist_class\", \n",
        "        frame=45, \n",
        "        segment_index=1,\n",
        "        value=lb_types.Checklist(\n",
        "            answer = [\n",
        "                \n",
        "                lb_types.ClassificationAnswer(\n",
        "                    name = \"second_checklist_answer\"\n",
        "                )\n",
        "            ]\n",
        "            )\n",
        "        )\n",
        "]\n",
        "\n",
        "\n",
        "## NDJSON\n",
        "\n",
        "frame_radio_classification_ndjson = {\n",
        "    \"name\": \"radio_class\", \n",
        "    \"answer\": { \"name\": \"first_radio_answer\", \"frames\": [{\"start\": 9, \"end\": 15}]}\n",
        "}\n",
        "\n",
        "## frame specific\n",
        "frame_checklist_classification_ndjson = {\n",
        "    \"name\": \"checklist_class\", \n",
        "    \"answer\": [\n",
        "        { \"name\": \"first_checklist_answer\" , \"frames\": [{\"start\": 29, \"end\": 35 }]},\n",
        "        { \"name\": \"second_checklist_answer\", \"frames\": [{\"start\": 39, \"end\": 45 }]} \n",
        "  ]      \n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### Global Classifications ####### \n",
        "\n",
        "## For global classifications use ClassificationAnnotation\n",
        "global_radio_annotation = [lb_types.ClassificationAnnotation(\n",
        "    name=\"radio_class_global\",\n",
        "    value=lb_types.Radio(answer = lb_types.ClassificationAnswer(name = \"first_radio_answer\"))\n",
        ")]\n",
        "\n",
        "global_checklist_annotation=[lb_types.ClassificationAnnotation(\n",
        "  name=\"checklist_class_global\", \n",
        "  value=lb_types.Checklist(\n",
        "      answer = [\n",
        "        lb_types.ClassificationAnswer(\n",
        "            name = \"first_checklist_answer\"\n",
        "        ), \n",
        "        lb_types.ClassificationAnswer(\n",
        "            name = \"second_checklist_answer\"\n",
        "        )\n",
        "      ]\n",
        "    )\n",
        " )]\n",
        "\n",
        "global_radio_classification_ndjson = {\n",
        "    \"name\": \"radio_class_global\", \n",
        "    \"answer\": { \"name\": \"first_radio_answer\"}\n",
        "}\n",
        "\n",
        "\n",
        "global_checklist_classification_ndjson = {\n",
        "    \"name\": \"checklist_class_global\", \n",
        "    \"answer\": [\n",
        "        { \"name\": \"first_checklist_answer\" },\n",
        "        { \"name\": \"second_checklist_answer\"} \n",
        "  ]      \n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########## Nested Global Classification ########### \n",
        "\n",
        "nested_radio_classification = {\n",
        "  'name': 'radio_question_nested',\n",
        "  'answer': {'name': 'first_radio_question'},\n",
        "  'classifications' : [\n",
        "    {'name': 'sub_question_radio', 'answer': {'name': 'sub_answer'}}\n",
        "   ]\n",
        "}\n",
        "\n",
        "nested_checklist_annotation_ndjson = {\n",
        "  \"name\": \"nested_checklist_question\",\n",
        "  \"answer\": [{\n",
        "      \"name\": \"first_checklist_answer\",\n",
        "      \"classifications\" : [\n",
        "        {\n",
        "          \"name\": \"sub_checklist_question\",\n",
        "          \"answer\": {\"name\": \"first_sub_checklist_answer\"}\n",
        "        }\n",
        "      ]\n",
        "  }]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "########## Classifications under frame base tools ##########\n",
        "\n",
        "# Frame base nested classifications do not support using the feature's name to extract ontology features. \n",
        "# For this single case we are going to use the classification's featureSchemaId and the answers' featureSchemaId \n",
        "# We will update the annotation object with the featureSchemaIds on step 5 after we create the ontology in step 2\n",
        "\n",
        "\n",
        "frame_bbox_with_checklist_subclass_ndjson = {\n",
        "    \"name\": \"bbox_class\",\n",
        "    \"segments\": [{\n",
        "        \"keyframes\": [\n",
        "            {\n",
        "            \"frame\": 10,\n",
        "            \"bbox\": {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              },\n",
        "            \"classifications\" : [\n",
        "              {'schemaId' : '', 'answer' : {'schemaId': '' }}\n",
        "            ]     \n",
        "          },\n",
        "          {  \n",
        "          \"frame\": 11,\n",
        "            \"bbox\": {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              },\n",
        "            \"classifications\" : [\n",
        "              {'schemaId' : '', 'answer' : {'schemaId': '' }}\n",
        "            ]  \n",
        "          },\n",
        "          {  \n",
        "          \"frame\": 13,\n",
        "            \"bbox\": {\n",
        "                \"top\": 146.0,\n",
        "                \"left\": 98.0,\n",
        "                \"height\": 382.0,\n",
        "                \"width\": 341.0\n",
        "              },\n",
        "            \"classifications\" : [\n",
        "              {'schemaId' : '', 'answer' : {'schemaId': '' }}\n",
        "            ]  \n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    ]\n",
        "}"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "##### Raster Segmentation ########\n",
        "\n",
        "instance_uri = \"https://storage.googleapis.com/labelbox-datasets/video-sample-data/mask_example.png\"\n",
        "instance_uri2 = \"https://storage.labelbox.com/cjhfn5y6s0pk507024nz1ocys%2F1d60856c-59b7-3060-2754-83f7e93e0d01-1?Expires=1666901963361&KeyName=labelbox-assets-key-3&Signature=t-2s2DB4YjFuWEFak0wxYqfBfZA\"\n",
        "\n",
        "\n",
        "video_mask_annotation=[\n",
        "    ## This doesn't work \n",
        "    lb_types.VideoMaskAnnotation(\n",
        "        name=\"video_mask\",\n",
        "        frames=[\n",
        "            lb_types.MaskFrame(index=10, instance_uri=instance_uri2)\n",
        "        ],\n",
        "        instances=[\n",
        "            lb_types.MaskInstance(color_rgb=(0,0,0), name=\"video_mask\")\n",
        "        ]     \n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "## This works\n",
        "video_mask_annotation_ndjson = {\n",
        "    'masks': {\n",
        "        'frames': [{\n",
        "            'index': 10,\n",
        "            'instanceURI': instance_uri2\n",
        "        }],\n",
        "        'instances': [\n",
        "            {\n",
        "                'colorRGB': (0, 0, 0),\n",
        "                'name': 'video_mask',\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "}\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "## Upload Annotations - putting it all together"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "### Step 1: Import data rows into Catalog"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "global_key = \"sample-video-2.mp4\"\n",
        "asset = {\n",
        "    \"row_data\": \"https://storage.googleapis.com/labelbox-datasets/video-sample-data/sample-video-2.mp4\", \n",
        "    \"global_key\": global_key,\n",
        "    \"media_type\": \"VIDEO\"\n",
        "}\n",
        "\n",
        "dataset = client.create_dataset(name=\"video_demo_dataset\")\n",
        "task = dataset.create_data_rows([asset])\n",
        "task.wait_till_done()\n",
        "print(\"Errors :\",task.errors)\n",
        "print(\"Failed data rows:\" ,task.failed_data_rows)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There are errors present. Please look at `task.errors` for more details\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors : Duplicate global keys found: sample-video-2.mp4\n",
            "Failed data rows: [{'message': 'Duplicate global keys found: sample-video-2.mp4', 'failedDataRows': [{'globalKey': 'sample-video-2.mp4', 'rowData': 'https://storage.googleapis.com/labelbox-datasets/video-sample-data/sample-video-2.mp4', 'attachmentInputs': []}]}]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 2: Create/select an ontology\n",
        "Your project should have the correct ontology setup with all the tools and classifications supported for your annotations, and the tool names and classification instructions should match the `name` fields in your annotations to ensure the correct feature schemas are matched.\n",
        "\n",
        "For example, when we create the bounding box annotation above, we provided the `name` as `bbox_video`. Now, when we setup our ontology, we must ensure that the name of my bounding box tool is also `bbox_video`. The same alignment must hold true for the other tools and classifications we create in our ontology.\n",
        "\n",
        "\n",
        "[Documentation for reference ](https://docs.labelbox.com/reference/import-text-annotations)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "ontology_builder = lb.OntologyBuilder(\n",
        "    tools=[\n",
        "        lb.Tool(tool=lb.Tool.Type.BBOX, name=\"bbox_video\"),\n",
        "        lb.Tool(tool=lb.Tool.Type.POINT, name=\"point_video\"),\n",
        "        lb.Tool(tool=lb.Tool.Type.LINE, name=\"line_video_frame\"),\n",
        "        lb.Tool(tool=lb.Tool.Type.RASTER_SEGMENTATION, name=\"video_mask\"),\n",
        "        lb.Tool(\n",
        "          tool=lb.Tool.Type.BBOX, name=\"bbox_class\",\n",
        "          classifications=[\n",
        "            lb.Classification(\n",
        "              class_type=lb.Classification.Type.RADIO,\n",
        "              name=\"bbox_radio\",\n",
        "              scope = lb.Classification.Scope.INDEX,\n",
        "              options=[\n",
        "                lb.Option(value=\"bbox_radio_answer_1\"),\n",
        "                lb.Option(value=\"bbox_radio_answer_2\"),\n",
        "                lb.Option(value=\"bbox_radio_answer_3\")\n",
        "              ]\n",
        "            )\n",
        "          ]\n",
        "        )\n",
        "    ],\n",
        "    classifications=[ \n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.CHECKLIST,\n",
        "            name=\"checklist_class\",\n",
        "            scope = lb.Classification.Scope.INDEX, ## Need to defined scope for frame classifications\n",
        "            options=[ \n",
        "                lb.Option(value=\"first_checklist_answer\"),\n",
        "                lb.Option(value=\"second_checklist_answer\")\n",
        "            ]\n",
        "        ),\n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.RADIO,\n",
        "            name=\"radio_class\",\n",
        "            scope = lb.Classification.Scope.INDEX,\n",
        "            options=[ \n",
        "                lb.Option(value=\"first_radio_answer\"),\n",
        "                lb.Option(value=\"second_radio_answer\")\n",
        "            ]\n",
        "        ),\n",
        "         lb.Classification(\n",
        "              class_type=lb.Classification.Type.RADIO,\n",
        "              name=\"radio_question_nested\",\n",
        "              options=[\n",
        "                  lb.Option(\"first_radio_question\",\n",
        "                        options=[\n",
        "                            lb.Classification(\n",
        "                                class_type=lb.Classification.Type.RADIO,\n",
        "                                name=\"sub_question_radio\",\n",
        "                                options=[lb.Option(\"sub_answer\")]\n",
        "                            )\n",
        "                        ]\n",
        "                  )\n",
        "              ] \n",
        "        ),\n",
        "        lb.Classification(\n",
        "          class_type=lb.Classification.Type.CHECKLIST,\n",
        "          name=\"nested_checklist_question\",\n",
        "          options=[\n",
        "              lb.Option(\"first_checklist_answer\",\n",
        "                options=[\n",
        "                  lb.Classification(\n",
        "                      class_type=lb.Classification.Type.CHECKLIST,\n",
        "                      name=\"sub_checklist_question\",\n",
        "                      options=[lb.Option(\"first_sub_checklist_answer\")]\n",
        "                  )\n",
        "              ]\n",
        "            )\n",
        "          ]\n",
        "        ),\n",
        "        lb.Classification(\n",
        "          class_type=lb.Classification.Type.RADIO, \n",
        "          name=\"radio_class_global\",\n",
        "          options=[ \n",
        "                lb.Option(value=\"first_radio_answer\"),\n",
        "                lb.Option(value=\"second_radio_answer\")\n",
        "            ]\n",
        "        ),\n",
        "        lb.Classification(\n",
        "          class_type=lb.Classification.Type.CHECKLIST,\n",
        "          name=\"checklist_class_global\",\n",
        "          options=[\n",
        "                lb.Option(value=\"first_checklist_answer\"),\n",
        "                lb.Option(value=\"second_checklist_answer\")\n",
        "          ]\n",
        "        )\n",
        "    ]  \n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\"Ontology Video Annotations\", ontology_builder.asdict(), media_type=lb.MediaType.Video)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 3: Create a labeling project \n",
        "Connect the ontology to the labeling project."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Project defaults to batch mode with benchmark quality settings if this argument is not provided\n",
        "# Queue mode will be deprecated once dataset mode is deprecated\n",
        "\n",
        "project = client.create_project(name=\"video_project_demo\",\n",
        "                                    queue_mode=lb.QueueMode.Batch,\n",
        "                                    media_type=lb.MediaType.Video)\n",
        "\n",
        "## connect ontology to your project\n",
        "project.setup_editor(ontology)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 4: Send a batch of data rows to the project"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Create batches\n",
        "\n",
        "# Create a batch to send to your MAL project\n",
        "batch = project.create_batch(\n",
        "  \"first-batch-video-demo2\", # Each batch in a project must have a unique name\n",
        "  global_keys=[global_key], # A paginated collection of data row objects\n",
        "  priority=5 # priority between 1(Highest) - 5(lowest)\n",
        ")\n",
        "\n",
        "print(\"Batch: \", batch)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch:  <Batch {\n",
            "    \"consensus_settings_json\": \"{\\\"numberOfLabels\\\":1,\\\"coveragePercentage\\\":0}\",\n",
            "    \"created_at\": \"2023-03-27 20:47:15+00:00\",\n",
            "    \"name\": \"first-batch-video-demo2\",\n",
            "    \"size\": 0,\n",
            "    \"uid\": \"8e8b2e20-cce0-11ed-a790-d9ca40a5be7a\",\n",
            "    \"updated_at\": \"2023-03-27 20:47:15+00:00\"\n",
            "}>\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 5: Create the annotations payload \n",
        "Create the annotations payload using the snippets of code above.\n",
        "\n",
        "Labelbox supports two formats for the annotations payload: NDJSON and Python Annotation types."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "#### Python Annotation Types"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "label = []\n",
        "annotations_list = [\n",
        "          checklist_annotation, \n",
        "          radio_annotation,\n",
        "          bbox_annotation, \n",
        "          point_annotation, \n",
        "          polyline_annotation,\n",
        "          global_checklist_annotation,\n",
        "          global_radio_annotation,\n",
        "          video_mask_annotation\n",
        "      ]\n",
        "\n",
        "flatten_list_annotations = [ann for ann_sublist in annotations_list for ann in ann_sublist] \n",
        "\n",
        "label.append(\n",
        "    lb_types.Label(\n",
        "        data=lb_types.VideoData(global_key=global_key),\n",
        "        annotations = flatten_list_annotations\n",
        "    )\n",
        ")\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "#### NDJSON annotations\n",
        "Here we create the complete `label_ndjson` payload of annotations. There is one annotation for each *reference to an annotation* that we created above."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "## For nested frame base classifications we need to pass a featureSchemaId instead of the name. \n",
        "\n",
        "features = project.ontology().normalized\n",
        "\n",
        "for i in features['tools']:\n",
        "  print(i)\n",
        "  if i['name'] == 'bbox_class':\n",
        "    ## Classification feature schema id\n",
        "    class_feature_schema_id = i['classifications'][0]['featureSchemaId']\n",
        "    ## Answer feature schema id (select one of the answers)\n",
        "    class_options_feature_schema_id = i['classifications'][0]['options'][0]['featureSchemaId']\n",
        "\n",
        "    ## Update the original annotation with the schema ids\n",
        "    for frame in frame_bbox_with_checklist_subclass_ndjson['segments']:\n",
        "      for k in frame['keyframes']:\n",
        "        k['classifications'][0].update(\n",
        "            {'schemaId': class_feature_schema_id , \n",
        "              'answer': {'schemaId': class_options_feature_schema_id}\n",
        "              }\n",
        "            )\n",
        "        "
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'schemaNodeId': 'clfravheu0dpf070p63nnfmuk', 'featureSchemaId': 'clfravheu0dpe070pd2615goi', 'required': False, 'name': 'bbox_video', 'tool': 'rectangle', 'color': '#ff0000', 'archived': 0, 'classifications': []}\n",
            "{'schemaNodeId': 'clfravheu0dph070p2myeaffx', 'featureSchemaId': 'clfravheu0dpg070p3pumgs9y', 'required': False, 'name': 'point_video', 'tool': 'point', 'color': '#cbff00', 'archived': 0, 'classifications': []}\n",
            "{'schemaNodeId': 'clfravheu0dpj070pgbfgao1x', 'featureSchemaId': 'clfravheu0dpi070pdijw57e4', 'required': False, 'name': 'line_video_frame', 'tool': 'line', 'color': '#00ff66', 'archived': 0, 'classifications': []}\n",
            "{'schemaNodeId': 'clfravheu0dpl070p04ia3z5w', 'featureSchemaId': 'clfravheu0dpk070p0gki3i2x', 'required': False, 'name': 'video_mask', 'tool': 'raster-segmentation', 'color': '#0066ff', 'archived': 0, 'classifications': []}\n",
            "{'schemaNodeId': 'clfravheu0dpv070pa7ltb9pg', 'featureSchemaId': 'clfravheu0dpm070pdkmvgp7v', 'required': False, 'name': 'bbox_class', 'tool': 'rectangle', 'color': '#cc00ff', 'archived': 0, 'classifications': [{'schemaNodeId': 'clfravheu0dpu070p7pglamwg', 'featureSchemaId': 'clfravheu0dpn070p1hg09p0b', 'archived': 0, 'required': False, 'instructions': 'bbox_radio', 'name': 'bbox_radio', 'type': 'radio', 'options': [{'schemaNodeId': 'clfravheu0dpp070pcm8dgl9y', 'featureSchemaId': 'clfravheu0dpo070p8l2f170v', 'label': 'bbox_radio_answer_1', 'value': 'bbox_radio_answer_1'}, {'schemaNodeId': 'clfravheu0dpr070p6zhd4h7d', 'featureSchemaId': 'clfravheu0dpq070p2p03c12u', 'label': 'bbox_radio_answer_2', 'value': 'bbox_radio_answer_2'}, {'schemaNodeId': 'clfravheu0dpt070pbc9vamu0', 'featureSchemaId': 'clfravheu0dps070pgl2ebb6s', 'label': 'bbox_radio_answer_3', 'value': 'bbox_radio_answer_3'}]}]}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "label_ndjson = []\n",
        "\n",
        "\n",
        "for annotation in [\n",
        "    point_annotation_ndjson,\n",
        "    bbox_annotation_ndjson,\n",
        "    polyline_frame_annotation_ndjson, \n",
        "    frame_checklist_classification_ndjson, \n",
        "    frame_radio_classification_ndjson,\n",
        "    nested_radio_classification,\n",
        "    nested_checklist_annotation_ndjson,\n",
        "    frame_bbox_with_checklist_subclass_ndjson,\n",
        "    global_radio_classification_ndjson,\n",
        "    global_checklist_classification_ndjson,\n",
        "    video_mask_annotation_ndjson       \n",
        "]:      \n",
        "  annotation.update({\n",
        "      'dataRow': {\n",
        "          'globalKey': global_key\n",
        "      }\n",
        "  })\n",
        "  label_ndjson.append(annotation)\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Step 6: Upload annotations to a project as pre-labels or completed labels\n",
        "For the purpose of this tutorial only run one of the label imports at once, otherwise the previous import might get overwritten."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "#### Model-Assisted Labeling (MAL)"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Upload MAL label for this data row in project\n",
        "upload_job_mal = lb.MALPredictionImport.create_from_objects(\n",
        "    client = client, \n",
        "    project_id = project.uid, \n",
        "    name=\"mal_import_job-\" + str(uuid.uuid4()), \n",
        "    predictions=label)\n",
        "\n",
        "upload_job_mal.wait_until_done();\n",
        "print(\"Errors:\", upload_job_mal.errors)\n",
        "print(\"Status of uploads: \", upload_job_mal.statuses)\n",
        "print(\"   \")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/aovalle/Desktop/labelbox-python-2/labelbox/data/serialization/ndjson/label.py:177: UserWarning: Nested classifications are not currently supported\n",
            "                    for video object annotations\n",
            "                    and will not import alongside the object annotations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Import failed.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[125], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m upload_job_mal \u001b[39m=\u001b[39m lb\u001b[39m.\u001b[39mMALPredictionImport\u001b[39m.\u001b[39mcreate_from_objects(\n\u001b[1;32m      3\u001b[0m     client \u001b[39m=\u001b[39m client, \n\u001b[1;32m      4\u001b[0m     project_id \u001b[39m=\u001b[39m project\u001b[39m.\u001b[39muid, \n\u001b[1;32m      5\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmal_import_job-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(uuid\u001b[39m.\u001b[39muuid4()), \n\u001b[1;32m      6\u001b[0m     predictions\u001b[39m=\u001b[39mlabel)\n\u001b[1;32m      8\u001b[0m upload_job_mal\u001b[39m.\u001b[39mwait_until_done();\n\u001b[0;32m----> 9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mErrors:\u001b[39m\u001b[39m\"\u001b[39m, upload_job_mal\u001b[39m.\u001b[39;49merrors)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStatus of uploads: \u001b[39m\u001b[39m\"\u001b[39m, upload_job_mal\u001b[39m.\u001b[39mstatuses)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m   \u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/labelbox-python-2/labelbox/schema/annotation_import.py:60\u001b[0m, in \u001b[0;36mAnnotationImport.errors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39mErrors for each individual annotation uploaded. This is a subset of statuses\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m* This information will expire after 24 hours.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait_until_done()\n\u001b[0;32m---> 60\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_remote_ndjson(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_file_url)\n",
            "File \u001b[0;32m~/Desktop/labelbox-python-2/labelbox/schema/annotation_import.py:131\u001b[0m, in \u001b[0;36mAnnotationImport._fetch_remote_ndjson\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mFetches the remote ndjson file and caches the results.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39m    ndjson as a list of dicts.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m AnnotationImportState\u001b[39m.\u001b[39mFAILED:\n\u001b[0;32m--> 131\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mImport failed.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n\u001b[1;32m    134\u001b[0m response\u001b[39m.\u001b[39mraise_for_status()\n",
            "\u001b[0;31mValueError\u001b[0m: Import failed."
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "#### Label Import"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "upload_job_label_import = lb.LabelImport.create_from_objects(\n",
        "    client = client,\n",
        "    project_id = project.uid, \n",
        "    name = \"label_import_job-\" + str(uuid.uuid4()),\n",
        "    labels=label\n",
        ")\n",
        "\n",
        "upload_job_label_import.wait_until_done()\n",
        "print(\"Errors:\", upload_job_label_import.errors)\n",
        "print(\"Status of uploads: \", upload_job_label_import.statuses)\n",
        "print(\"   \")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors: [{'uuid': 'a374c173-8aa7-4de8-894a-18b36f3e1fe8', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'FAILURE', 'errors': [{'name': 'FetchImageError', 'message': 'Error while downloading image from url: https://api.labelbox.com/masks/feature/clfr7k2sx00033b6ja7dxd7ap/1', 'additionalInfo': None}]}]\n",
            "Status of uploads:  [{'uuid': '68ca10d7-b0ba-4b3e-ae5c-a3877ec250c7', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '161f866a-2734-49d6-8303-453e2c9da4fd', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '70312492-7031-4a96-b19d-4ed25d968903', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': 'c948f83f-43f1-4a1e-9762-57d70981c6da', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '08bcf1fa-2810-492d-bbb5-d25b9e01da25', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '8baab052-83af-4961-823f-45a9bad23dcc', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '5eb95e70-d63f-4de5-9004-7596f34c098d', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '7391a220-131d-41ca-84e6-60e9d8ffc8ba', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': 'e94436d1-95c5-48f9-b9ec-383913b4bfe8', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': '8214045e-084b-4af8-bf95-8c37ec9d561f', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'SUCCESS'}, {'uuid': 'a374c173-8aa7-4de8-894a-18b36f3e1fe8', 'dataRow': {'id': 'clfco73at0080079n5dhm9y3a', 'globalKey': 'sample-video-2.mp4'}, 'status': 'FAILURE', 'errors': [{'name': 'FetchImageError', 'message': 'Error while downloading image from url: https://api.labelbox.com/masks/feature/clfr7k2sx00033b6ja7dxd7ap/1', 'additionalInfo': None}]}]\n",
            "   \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "### Optional deletions for cleanup"
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {},
      "source": [
        "# Delete Project\n",
        "# project.delete()\n",
        "# dataset.delete()\n"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}